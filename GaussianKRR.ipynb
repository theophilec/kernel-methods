{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "GaussianKRR.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTqESsNHy0Yl"
      },
      "source": [
        "# Gaussian KRR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40eciVpdcQym"
      },
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cvxpy\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVgAz4afypZq"
      },
      "source": [
        "## Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InSiEqxZcQy5"
      },
      "source": [
        "# KRR implementation for Gaussian Kernel\n",
        "def findBestParamsAndPredict(x_train, x_test, y_train, y_test, x_candidate):\n",
        "    # Set param grid for lambda (L) and sigma (S)\n",
        "    L, S = np.meshgrid(np.logspace(-5,-2,25), np.logspace(-1.5,0.5,25))\n",
        "    L, S = L.flatten(), S.flatten()\n",
        "    dist = np.linalg.norm((x_train[:,None]-x_train), axis = 2)**2\n",
        "    dist_test = np.linalg.norm((x_test[:,None]-x_train), axis = 2)**2\n",
        "    preds_tr = []\n",
        "    preds_tt = []\n",
        "\n",
        "    # Compute accuracy for all params\n",
        "    indices = tqdm(range(len(L)), position = 0, leave = True)\n",
        "    for i in indices:\n",
        "        lambd, sigma = L[i], S[i]\n",
        "\n",
        "        # Train (compute alpha)\n",
        "        n = dist.shape[0]\n",
        "        K = np.exp(-dist/sigma**2)\n",
        "        alpha = np.linalg.solve(K+lambd * n * np.eye(n), y_train)\n",
        "\n",
        "        # Test\n",
        "        K_test = np.exp(-dist_test/sigma**2)\n",
        "\n",
        "        # Predict\n",
        "        preds_train = 1 * ((K @ alpha) > 1/2)\n",
        "        preds_test = 1 * ((K_test @ alpha) > 1/2)\n",
        "        preds_tr.append(np.sum(preds_train == y_train)/x_train.shape[0])\n",
        "        preds_tt.append(np.sum(preds_test == y_test)/x_test.shape[0])\n",
        "    \n",
        "    # Extract optimal params\n",
        "    idx = np.argmax(preds_tt)\n",
        "    opt_lambda, opt_sigma = L[idx], S[idx]\n",
        "    print(\"Optimal parameters: lambda = {}, sigma = {}\".format(opt_lambda, opt_sigma))\n",
        "    print(\"Training accuracy is: {}\".format(preds_tr[idx]))\n",
        "    print(\"Test accuracy is: {}\".format(preds_tt[idx]))\n",
        "    \n",
        "    \n",
        "    # Predict\n",
        "    dist_candidate = np.linalg.norm((x_candidate[:,None]-x_train), axis = 2)**2\n",
        "    K = np.exp(-dist/opt_sigma**2)\n",
        "    alpha = np.linalg.solve(K+opt_lambda * n * np.eye(n), y_train)\n",
        "    K_candidate = np.exp(-dist_candidate/opt_sigma**2)\n",
        "    predictions = 1 * ((K_candidate @ alpha) > 1/2)\n",
        "    return predictions"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmrUyHPucQzJ"
      },
      "source": [
        "# Format data for submission\n",
        "def parse_output(predictions, filename):\n",
        "    '''\n",
        "        predictions : list of predictions\n",
        "    '''\n",
        "    predictions = np.sign(predictions)\n",
        "    predictions[predictions == -1] = 0\n",
        "    \n",
        "    with open(filename, 'w') as f:\n",
        "        f.write(\"Id,Bound\\n\")\n",
        "        count = 0\n",
        "        for i in range(predictions.shape[0]):\n",
        "            f.write(\"{},{}\\n\".format(count, int(predictions[i])))\n",
        "            count += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeiU5v6AysjS"
      },
      "source": [
        "## Prediction on each dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQIDddjtxBCk"
      },
      "source": [
        "# Compute predictions\n",
        "preds = []\n",
        "for k in range(3):\n",
        "    print(\"Dataset nÂ°{}\".format(k))\n",
        "    # Data loading\n",
        "    train = np.loadtxt(open(\"data/Xtr{}_mat100.csv\".format(k), \"rb\"), delimiter=\" \")\n",
        "    test = np.loadtxt(open(\"data/Xte{}_mat100.csv\".format(k), \"rb\"), delimiter=\" \")\n",
        "    Y = pd.read_csv('data/Ytr{}.csv'.format(k))['Bound'].values\n",
        "    \n",
        "    # Training set\n",
        "    x_train, x_test, y_train, y_test = train_test_split(train, Y, test_size=0.2, random_state=42)\n",
        "    \n",
        "    # Find best parameters and predict\n",
        "    predictions = findBestParamsAndPredict(x_train, x_test, y_train, y_test, test)\n",
        "    preds.append(predictions)\n",
        "\n",
        "# Export for submission\n",
        "parse_output(np.concatenate(preds), 'test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpaSmFKQywzG"
      },
      "source": [
        "## Global Training and Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bcw0rzzQeKJ5"
      },
      "source": [
        "# Load different datasets\n",
        "train, test, Y = [], [], []\n",
        "for k in range(3):\n",
        "    train.append(np.loadtxt(open(\"data/Xtr{}_mat100.csv\".format(k), \"rb\"), delimiter=\" \"))\n",
        "    test.append(np.loadtxt(open(\"data/Xte{}_mat100.csv\".format(k), \"rb\"), delimiter=\" \"))\n",
        "    Y.append(pd.read_csv('data/Ytr{}.csv'.format(k))['Bound'].values)\n",
        "\n",
        "# Combine datasets\n",
        "train = np.concatenate(train)\n",
        "test = np.concatenate(test)\n",
        "Y = np.concatenate(Y)\n",
        "\n",
        "# Create train/test sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(train, Y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Find best parameters and predict\n",
        "predictions = findBestParamsAndPredict(x_train, x_test, y_train, y_test, test)\n",
        "\n",
        "# Export for submission\n",
        "parse_output(np.concatenate(preds), 'test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbF5l7DBwQlS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}