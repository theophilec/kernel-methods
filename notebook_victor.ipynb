{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cvxpy\n",
    "import time\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'algos' from '/home/victor/Data/Mines-ParisTech/M2/mva/S2/km/kernel-methods/algos.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io_utils\n",
    "import kernels\n",
    "import algos\n",
    "from importlib import reload\n",
    "reload(kernels)\n",
    "reload(io_utils)\n",
    "reload(algos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create experiment and load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "exp = io_utils.Experiment()\n",
    "exp.create_new_experiment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load previous experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:28<00:00,  9.64s/it]\n"
     ]
    }
   ],
   "source": [
    "kernels_wd_train = exp.load('kernels/SS_5_03.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum vp is -0.000+0.000j\n",
      "Minimum vp is -0.000+0.000j\n",
      "Minimum vp is -0.000+0.000j\n"
     ]
    }
   ],
   "source": [
    "# Takes ~ 1min\n",
    "for kn in kernels_wd_train:\n",
    "    print(\"Minimum vp is {:.3f}\".format(np.min(np.linalg.eigvals(kn))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation with 5 slices. Training set: 1600, Validation set: 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [01:31<00:00, 18.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: 0.5994842503189409\n",
      "Score 1: 0.631\n",
      "Score 2: 0.6405000000000001\n",
      "Score 3: 0.7265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(algos)\n",
    "TRIALS = 10\n",
    "\n",
    "lambda_vals = np.logspace(-2, 0, TRIALS)\n",
    "\n",
    "krr = algos.KernelRidgeRegression()\n",
    "# svm = algos.SVM()\n",
    "\n",
    "krr.cross_validate(exp, kernels_wd_train, lambda_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute substring kernel for all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kern_ss = kernels.WeightedDegreeKernel(9)\n",
    "kern_ss = kernels.SubstringKernel(3, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_wd_train = []\n",
    "\n",
    "with mp.Pool(9) as pool:\n",
    "    # Compute kernels\n",
    "\n",
    "\n",
    "    for n in range(2,3):\n",
    "        print(\"Processing dataset {}\".format(n))\n",
    "        n_train = 400#exp.raw[n].shape[0]\n",
    "\n",
    "        t = time.time()\n",
    "        args = [(exp.raw[n][i], exp.raw[n][j]) for i in range(n_train) for j in range(i, n_train) ]\n",
    "        result = pool.map(kern_ss.computeKernel, args)\n",
    "        e = time.time()\n",
    "        print(\"Kernel computation took {:.2f} seconds\".format(e-t))\n",
    "\n",
    "        count = 0\n",
    "        K = np.zeros((n_train, n_train))\n",
    "        for i in range(n_train):\n",
    "            for j in range(i, n_train):\n",
    "                K[i,j] = result[count]\n",
    "                count +=1\n",
    "\n",
    "        for i in range(n_train):\n",
    "            for j in range(0, i):\n",
    "                K[i,j] = K[j,i]\n",
    "\n",
    "        kernels_wd_train.append(K.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(np.linalg.eigvals(kernels_wd_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If needed, save experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_name = \"wd_7_02\"\n",
    "exp.save('kernels/{}'.format(kernel_name), kernels_train, kernels_val, kernels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    np.savetxt(\"kernels/substring_7_02_trainval_{}.txt\".format(i), kernels_wd_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Compute matrices needed for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset 0\n",
      "Processing dataset 1\n",
      "Processing dataset 2\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "exp.load_all_test_datasets()\n",
    "\n",
    "kernels_test = []\n",
    "with mp.Pool(9) as pool:\n",
    "    for i in range(3):    \n",
    "        print(\"Processing dataset {}\".format(i))\n",
    "        n1, n2 = exp.raw[i].shape[0], exp.raw_test[i].shape[0]\n",
    "        args = [(exp.raw[i][j], exp.raw_test[i][k]) for j in range(n1) for k in range(n2) ]\n",
    "        result = pool.map(kern_ss.computeKernel, args)\n",
    "\n",
    "        kernel_test = np.zeros((n1, n2))\n",
    "\n",
    "        count = 0\n",
    "        for k in range(n1):\n",
    "            for l in range(n2):\n",
    "                kernel_test[k,l] = result[count]\n",
    "                count +=1\n",
    "\n",
    "        kernels_test.append(kernel_test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(3):\n",
    "#     np.savetxt('kernels/substring_3_01_train_test_{}.txt'.format(i), kernels_test[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start here to load saved kernels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_kernel = kernels.LinearKernel()\n",
    "K_linear_train = []\n",
    "for i in range(3):\n",
    "    K_linear_train.append(linear_kernel.computeVectorizedKernel(exp.feats[i], exp.feats[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel = kernels.GaussianKernel(1)\n",
    "K_gauss_train, K_gauss_val = [], []\n",
    "for i in range(3):\n",
    "    K_gauss_train.append(gaussian_kernel.computeVectorizedKernel(exp.feats[i], exp.feats[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Prediction \n",
    "reload(algos)\n",
    "lambd_substring = 1e-1\n",
    "lambd_gauss = 4e-4\n",
    "lambd_linear = 1e-2\n",
    "lambd_svm = 2e-2\n",
    "TRIALS = 30\n",
    "\n",
    "lambda_vals = np.logspace(-7, -3, TRIALS)\n",
    "\n",
    "all_preds = []\n",
    "\n",
    "krr = algos.KernelRidgeRegression()\n",
    "svm = algos.SVM()\n",
    "\n",
    "# weights = np.ones((3,2))\n",
    "\n",
    "# for i in range(3):\n",
    "#     krr.fit(K_linear_train[i], exp.labels_train[i], lambd_substring)\n",
    "#     error_1 = krr.evaluatePerformance(kernels_val[i], exp.labels_val[i])\n",
    "#     predictions_1 = np.einsum('i, ij->j', krr.alpha, kernels_val[i])\n",
    "#     w_1 = 1-error_1\n",
    "    \n",
    "krr.fit(kernels_wd_train[i], exp.labels_train[i], lambd_linear)\n",
    "error_4 = krr.evaluatePerformance(kernels_wd_val[i], exp.labels_val[i])\n",
    "w_4 = (1-error_4)\n",
    "predictions_4 = np.einsum('i, ij->j', krr.alpha, kernels_wd_val[i])\n",
    "\n",
    "#     krr.fit(K_gauss_train[i], exp.labels_train[i], lambd_gauss)\n",
    "#     error_3 = krr.evaluatePerformance(K_gauss_val[i], exp.labels_val[i])\n",
    "#     w_3 = (1-error_3)\n",
    "#     predictions_3 = np.einsum('i, ij->j', krr.alpha, K_gauss_val[i])\n",
    "    \n",
    "#     n = K_gauss_train[i].shape[0]\n",
    "#     training_labels_ret = exp.labels_train[i].copy()\n",
    "#     training_labels_ret[training_labels_ret == -1 ] = 0\n",
    "        \n",
    "#     global_error =  w_1 / (w_1 +w_3+w_4) *predictions_1 + w_3 / (w_1 +w_3+w_4) * predictions_3 + w_4 / (w_1 +w_3+w_4) * predictions_4\n",
    "    \n",
    "#     print(np.round(1-np.sum(np.sign(global_error) != np.sign(exp.labels_val[i])) / exp.labels_val[i].shape[0],3))\n",
    "#     print(\"----\")\n",
    "\n",
    "# Test\n",
    "#     pred_test = krr.predict(kernel_tests[i])\n",
    "#     all_preds.append(pred_test.copy())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernels_normalized = []\n",
    "for n in range(3):\n",
    "    tmp = np.zeros_like(kernels_wd_train[0])\n",
    "    for i in range(kernels_wd_train[0].shape[0]):\n",
    "        for j in range(kernels_wd_train[0].shape[0]):\n",
    "            tmp[i,j] = kernels_wd_train[n][i,j] / (np.sqrt(kernels_wd_train[n][i,i] * kernels_wd_train[n][j,j]))\n",
    "    kernels_normalized.append(tmp.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
